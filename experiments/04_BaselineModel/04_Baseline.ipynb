{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42a1acc",
   "metadata": {},
   "source": [
    "# Baseline Model in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf9fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.special import logit\n",
    "from sklearn.metrics import accuracy_score, log_loss as cross_entropy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d938a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "rng = default_rng(seed=1234321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d993b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from masterthesis.data import load_acinar, data_dir\n",
    "# load the python AnnData object\n",
    "acinar_ann = load_acinar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "245f5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset shape\", acinar_ann.X.shape)\n",
    "print(\"First gene:\", acinar_ann.X[:,0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c53b44e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Access Gene Names\n",
    "acinar_ann.var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2cc30fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# select one gene\n",
    "acinar_ann[:, acinar_ann.var_names.str.match(\"A1CF\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d7809d",
   "metadata": {},
   "source": [
    "### R Gene selection and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a3fd1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling in R with seed 1234\n",
    "test_idx = [284, 336, 406, 101, 111, 393, 133, 400, 388, 98, 103, 214, 90, 326, 79, 372, 270, 382, 184, 62, 4, 403, 149, 40, 212, 195, 93, 122, 66, 175, 379, 304, 108, 131, 343, 41, 115, 228, 328, 298, 299]\n",
    "train_idx = list(set(range(acinar_ann.X.shape[0])) - set(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc58a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected Genes after preprocessing in R\n",
    "sel_genes = [\"REG3A\", \"AMY2A\", \"MT2A\", \"OLFM4\",\n",
    "             \"SYCN\", \"CELA2B\", \"FGL1\", \"AMY2B\",\n",
    "             \"MT1G\", \"TM4SF1\", \"CELA2A\", \"PDK4\", \n",
    "             \"TACSTD2\", \"CD44\", \"PNLIPRP2\", \"ALB\", \n",
    "             \"ERP27\", \"LDHA\", \"REG3G\", \"CTRL\", \"CLPS\",\n",
    "             \"FOS\", \"HSPA8\", \"SERPINA3\", \"CELA3B\", \"CRP\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e698b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = np.array([int(x) for x in acinar_ann.obs.donor_age])\n",
    "k = len(np.unique(y))\n",
    "X_train, X_test, y_train, y_test = train_test_split(acinar_ann[:,sel_genes].X, y, \n",
    "                                                    test_size=0.1, \n",
    "                                                    stratify=y,\n",
    "                                                    random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd408d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old approach based on the indexes from R\n",
    "#y_train = y[train_idx]\n",
    "#y_test = y[test_idx]\n",
    "\n",
    "#X_train = acinar_ann[test_idx, sel_genes].X\n",
    "#X_test = acinar_ann[train_idx, sel_genes].X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e11daef",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecb3bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test X:\", X_test.shape)\n",
    "print(\"Test y:\", y_test.shape)\n",
    "print(\"Train X:\", X_train.shape)\n",
    "print(\"Train y:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3788e371",
   "metadata": {},
   "source": [
    "## Model 1: mord\n",
    "\n",
    "**Result: It was not possible to achieve the necessary sparsity with this model. Only L2 regularization is required. The thresholds seem not entirely plausible**\n",
    "\n",
    "[Reference 1](https://medium.datadriveninvestor.com/logistic-regression-simple-multinomial-and-ordinal-b2bc886bb974) [Reference 2](https://pythonhosted.org/mord/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e66f6b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mord import LogisticAT, LogisticIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "babd36db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform y into a series of subsequent labels [0,1,2 ...]\n",
    "transf = dict(zip(np.unique(y),\n",
    "                  np.arange(0, len(np.unique(y)))))\n",
    "                        \n",
    "y_train_trans = np.array([transf[e] for e in y_train])\n",
    "y_test_trans = np.array([transf[e] for e in y_test])\n",
    "\n",
    "# reordering, such that yi < yi+1\n",
    "train_reorder = np.argsort(y_train_trans)\n",
    "test_reorder = np.argsort(y_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f69f7ff8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# all-threshold fit\n",
    "regressor = LogisticAT(verbose=0, alpha=0.1)\n",
    "regressor.fit(X_train, y_train_trans)\n",
    "regressor.score(X_test, y_test_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b60334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# immediate-threshold fit\n",
    "regressor = LogisticIT(verbose=0, alpha=0, )\n",
    "regressor.fit(X_train[train_reorder], y_train_trans[train_reorder])\n",
    "regressor.score(X_test[test_reorder], y_test_trans[test_reorder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feef9d0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regressor.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f65a05b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "regressor.theta_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc7e1b6",
   "metadata": {},
   "source": [
    "## Model 2: Ordered Multinomial Regression (statsmodels) \n",
    "\n",
    "**Result: Introducing sparsity, or even using any regularizer seems to not be supported, or at least I didn't find a way.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c612834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b490d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod_prob = OrderedModel(y_train,\n",
    "                        X_train,\n",
    "                        distr='logit')\n",
    "\n",
    "res_prob = mod_prob.fit(method='bfgs')\n",
    "res_prob.summary().tables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4816fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_prob.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438cde48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = res_prob.model.predict(res_prob.params, exog=X_test)\n",
    "print(\"Predictions:\", predictions.argmax(1))\n",
    "print(\"Ground Truth:\", y_test_trans)\n",
    "print(\"Cross Entropy:\", cross_entropy_score(y_test, predictions, labels=np.unique(y)))\n",
    "print(\"Accuracy:\", accuracy_score(predictions.argmax(1), y_test_trans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72c7457",
   "metadata": {},
   "source": [
    "## Model 3: Multinomial Regression (sklearn)\n",
    "\n",
    "**Results:** \n",
    "- Introduction of sparsity worked well with the l1 penalty\n",
    "- Prediction results were on par with the other methods\n",
    "- However, since this is solved as a multinomial regression problem, one set of parameters is fit for each prediction class. This introduces a new problem for selection of parameters: The weights have to be aggregated, which has eliminated the sparsity with the attempted approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b26393",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sk_model = LogisticRegression(penalty=\"l1\",\n",
    "                              multi_class=\"multinomial\", # \"auto\", \"ovr\", \"multinomial\"\n",
    "                              solver=\"saga\",\n",
    "                              random_state=12345)\n",
    "sk_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344b7d15",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Model coefficients shape:\", sk_model.coef_.shape)\n",
    "print(\"Train score:\", sk_model.score(X_train, y_train))\n",
    "print(\"Test score:\", sk_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33a038c",
   "metadata": {},
   "source": [
    "#### Aggregation of Weights from multinomial model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7baf46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# defines a threshold below which a gene is not considered significant\n",
    "# this is arbitrary, there is no way of defining this\n",
    "sparsity_threshold = 0.0001\n",
    "\n",
    "skl_mm_added = np.add.reduce(sk_model.coef_, axis=0)\n",
    "print(\"Added weights from Muli-Class model\")\n",
    "print(\"sparsity:\", sum(np.abs(skl_mm_added) < sparsity_threshold))\n",
    "\n",
    "skl_mm_mean = skl_mm_added / sk_model.coef_.shape[1]\n",
    "print(\"Average weights from Muli-Class model\")\n",
    "print(\"sparsity:\", sum(np.abs(skl_mm_mean) < sparsity_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3528d755",
   "metadata": {},
   "source": [
    "## Models 4-6: Binary LogisticRegression (sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0ead1a",
   "metadata": {},
   "source": [
    "### Convert the data\n",
    "\n",
    "- The labels are converted to binary, such that the threshold from 0-1 corresponds from changing from label $l_i$ to $l_{i+1}$. $k$ copies of the label vector are concatenated such that for every vector $j$ the labels  $l_i$ with $i<j$ are converted to 0 and the labels $i\\ge j$ are converted to 1.\n",
    "- The count matrix is extended with copies of itself, to fit the converted label vector FOR NOW. For big problems, it could suffice to have just one label vector and perform and iterative training.\n",
    "- To train the thresholds, $k$ columns are added to the count matrix and initialized to zero. Each column column represents the threshold for a label $l_i$ and is set to 1, exactly  where that label $l_1$ occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bin_y(y_orig):\n",
    "    y_classes = np.unique(y_orig)\n",
    "    k = len(y_classes)\n",
    "\n",
    "    y_bin = []\n",
    "    for ki in range(1,k):\n",
    "        thresh = y_classes[ki]\n",
    "        y_bin += [int(x>=thresh) for x in y_orig]\n",
    "\n",
    "    y_bin = np.array(y_bin)\n",
    "    \n",
    "    return y_bin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094cbf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_bin_X(X_orig, k):\n",
    "\n",
    "    # X training matrix\n",
    "    X_bin = np.concatenate([X_orig.copy()] * (k-1))\n",
    "    # Add thresholds\n",
    "    num_el = X_orig.shape[0] * (k-1)\n",
    "\n",
    "    for ki in range(k-1):\n",
    "        temp = np.repeat(0, num_el).reshape(X_orig.shape[0], (k-1))\n",
    "        temp[:,ki] = 1\n",
    "        if ki > 0:\n",
    "            thresholds = np.concatenate([thresholds, temp])\n",
    "        else:\n",
    "            thresholds = temp\n",
    "\n",
    "    X_bin = np.concatenate([X_bin, thresholds], axis=1)\n",
    "\n",
    "    return X_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2e104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bin = to_bin_y(y_train)\n",
    "print(\"y_train:\", len(y_train_bin))\n",
    "\n",
    "y_test_bin = to_bin_y(y_test)\n",
    "print(\"y_test:\", len(y_test_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986de3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bin = to_bin_X(X_train, k=np.unique(y).size)\n",
    "print(\"X_train_bin:\", X_train_bin.shape)\n",
    "\n",
    "X_test_bin = to_bin_X(X_test, k=np.unique(y).size)\n",
    "print(\"X_test_bin:\", X_test_bin.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2374c4aa",
   "metadata": {},
   "source": [
    "### Model 4: LogisticRegression (sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926af278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sk_binlogreg_model = LogisticRegression(penalty=\"l1\", \n",
    "                                  fit_intercept=False,\n",
    "                                  max_iter=10000,\n",
    "                                  solver=\"liblinear\",\n",
    "                                  random_state=1234,\n",
    "                                  C=0.01  # Inverse of regularization strength -> controls sparsity in our case!\n",
    "                                 )\n",
    "\n",
    "sk_binlogreg_model.fit(X_train_bin, y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94cb891",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score:\",sk_binlogreg_model.score(X_train_bin, y_train_bin))\n",
    "print(\"Test score:\",sk_binlogreg_model.score(X_test_bin, y_test_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e2408",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sk_binlogreg_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea711fa",
   "metadata": {},
   "source": [
    "## Binary Logistic Regression with GLMnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5882a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glmnet import LogitNet\n",
    "\n",
    "# Note: Alpha is the regularization mixing parameter: alpha=1 -> L1, alpha=0 -> L2, 0<alpha<1 -> elastic net \n",
    "glmnet_model = LogitNet(alpha=1,\n",
    "                        fit_intercept=False,\n",
    "                        standardize=False, # already standardized\n",
    "                        random_state=1234,\n",
    "                        max_iter=10000)\n",
    "glmnet_model.fit(X_train_bin, y_train_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90143035",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Train score: \", glmnet_model.score(X_train_bin, y_train_bin))\n",
    "print(\"Test score: \", glmnet_model.score(X_test_bin, y_test_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41071ea9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glmnet_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c88de7",
   "metadata": {},
   "source": [
    "## SGD with mini Batches\n",
    "\n",
    "To reduce the memory load, this introduces a sampling method with an iterative training paradigm\n",
    "\n",
    "ToDo: \n",
    "\n",
    "    - Construct matrix on the fly\n",
    "    - Check convergence / early stopping\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ffaa91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_model = SGDClassifier(loss=\"log_loss\",\n",
    "                          penalty=\"l1\",\n",
    "                          alpha=0.01,  # = lambda in paper!! Very important to tune for the desired sparsity!\n",
    "                          fit_intercept=False,\n",
    "                          n_jobs=1)\n",
    "\n",
    "cur_iter = 0\n",
    "max_iter = 10\n",
    "n_batches = 2\n",
    "\n",
    "while cur_iter < max_iter:\n",
    "    if (cur_iter > 0 and cur_iter % 2 == 0):\n",
    "        print(\"Iter: \", cur_iter, \"Train score: \", sgd_model.score(X_batch, y_batch))\n",
    "    \n",
    "    cur_iter += 1\n",
    "    \n",
    "    # fit from samples of the big matrix\n",
    "    # TODO: Sampling from the big matrix directly is just for PoP,\n",
    "    # and eliminates the purpose. Only the binarized y-vector should\n",
    "    # be created and the indexes taken from the log count matrix.\n",
    "    sampled_indices = np.random.randint(X_train_bin.shape[0], size=X_train_bin.shape[0])\n",
    "\n",
    "    start = 0\n",
    "    for i in range(1, n_batches+1):\n",
    "        end = (i * X_train_bin.shape[0] // n_batches)\n",
    "        idx = sampled_indices[start:end]\n",
    "        X_batch = X_train_bin[idx,:]\n",
    "        y_batch = y_train_bin[idx]\n",
    "        start = end\n",
    "        sgd_model.partial_fit(X_batch, y_batch, classes=np.unique(y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249cd2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score:\", sgd_model.score(X_train_bin, y_train_bin))\n",
    "print(\"Test score:\", sgd_model.score(X_test_bin, y_test_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f06585",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sgd_model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6b5cff",
   "metadata": {},
   "source": [
    "# Compare Parameters\n",
    "\n",
    "- To compare parameters we first fincd the best regularization strength\n",
    "    * The best regularization has the highest score across 5-fold CV\n",
    "    * To increase sparsity, we choose the parameter with highest regularization, that lies within 1 standard error of the optimum\n",
    "- Then we do N fits with different seeds and collect the parameter values. \n",
    "- Finally we compare the distributions of the collected parameter values visually and wrt KL-divergence\n",
    "\n",
    "The models to investigate:  sklearn LinRegressor, GLMnet Mmodel, SGD LinRegressor, and Psupertime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff745b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_validate, GridSearchCV\n",
    "\n",
    "n_folds = 5\n",
    "kf = StratifiedKFold(n_splits=n_folds)\n",
    "\n",
    "# elongate the origial non-binarized y-train data\n",
    "# to enable stratification\n",
    "y_train_elong = np.repeat(y_train, k-1)\n",
    "\n",
    "cv_splits = kf.split(X_train_bin, y_train_elong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88520616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss, make_scorer\n",
    "\n",
    "scorers = {\n",
    "    \"accuracy\": accuracy_score,\n",
    "    \"cross-entropy\": log_loss\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046e86f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dof(params):\n",
    "    return np.count_nonzero(params != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e7fee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_res_to_df(cv_results, scorers, reg_params=None):\n",
    "    df = pd.DataFrame.from_dict(cv_results, orient=\"index\").stack().to_frame()\n",
    "    df = pd.DataFrame(df[0].values.tolist(), index=df.index)\n",
    "    \n",
    "    if reg_params is not None:\n",
    "        df.columns = [\"L=%s\" % x for x in reg_params]\n",
    "\n",
    "    for scorer in scorers.keys():\n",
    "        df.loc[(\"mean\", scorer), :] = df.xs(scorer, level=1).mean(axis=0)\n",
    "    df.loc[(\"mean\", \"dof\"), :] = df.xs(\"dof\",level=1).mean(axis=0)\n",
    "    \n",
    "    return df.T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c649ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_param(res_df, reg_params, lower_increases_reg=True):\n",
    "    trimmed = res_df.loc[res_df[(\"mean\", \"dof\")] != 0]\n",
    "    trimmed_max = trimmed[(\"mean\", \"accuracy\")].max()\n",
    "    trimmed_std = trimmed[(\"mean\", \"accuracy\")].std()\n",
    "    thresh = trimmed_max - trimmed_std\n",
    "    above = trimmed[trimmed[(\"mean\", \"accuracy\")] > thresh]\n",
    "\n",
    "    if lower_increases_reg:\n",
    "        idx = above.iloc[-1].name\n",
    "    else:\n",
    "        idx = above.iloc[0].name\n",
    "\n",
    "    print(\"max:\", trimmed_max, \"std:\", trimmed_std, \"thresh:\", thresh)\n",
    "    print(\"Best average fit:\", trimmed.loc[idx])\n",
    "    print(\"Best parameter:\", reg_params[idx])\n",
    "    \n",
    "    return reg_params[idx]        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5174e0f",
   "metadata": {},
   "source": [
    "**Important result: Choice of regularization path (lambda path) is critical for selection of best parameter!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30450388",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_params = np.concatenate((np.linspace(1,10,10)[::-1], np.logspace(1, 15, 40, base=0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7435219",
   "metadata": {},
   "source": [
    "## SKLearn linregressor:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cd905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRIDSEARCH:\n",
    "# ------------\n",
    "\n",
    "#scorers = {\n",
    "#    \"accuracy\": make_scorer(accuracy_score),\n",
    "#    \"cross-entropy-loss\": make_scorer(log_loss)\n",
    "#}\n",
    "#params = {\"C\": [1, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001]}\n",
    "#sk_binlogreg_model = LogisticRegression(penalty=\"l1\", \n",
    "#                                  fit_intercept=False,\n",
    "#                                  max_iter=10000,\n",
    "#                                  solver=\"liblinear\",\n",
    "#                                  random_state=1234)\n",
    "#sk_binlogreg_cv = GridSearchCV(sk_binlogreg_model,\n",
    "#                               param_grid=params,\n",
    "#                               refit=False,\n",
    "#                               cv=kf.split(X_train_bin, y_train_elong),\n",
    "#                               scoring=scorers)\n",
    "#sk_binlogreg_cv.cv_results_\n",
    "\n",
    "# Problem: Does not save parameters of intermediate models: Tracking of sparsity not possible\n",
    "# Let's do it ourselves ..\n",
    "# But, still interesting for the final package!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3336d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#reg_params = [1, 0.75, 0.5, 0.25, 0.1, 0.075, 0.05, 0.025, 0.01, 0.005, 0.001, 0.0005]\n",
    "sk_reg_params = np.concatenate((np.linspace(1,5,10)[::-1], np.logspace(1, 15, 40, base=0.5)))\n",
    "cv_results = dict()\n",
    "\n",
    "for i, (cv_train_idx, cv_test_idx) in enumerate(kf.split(X_train_bin, y_train_elong)):\n",
    "    \n",
    "    s = \"split_%s\" % i\n",
    "    print(s)\n",
    "\n",
    "    cv_results[s] = dict()\n",
    "    cv_results[s][\"dof\"] = []\n",
    "    for scorer in scorers.keys():\n",
    "        cv_results[s][scorer] = []\n",
    "    \n",
    "    for c in sk_reg_params:\n",
    "        model = LogisticRegression(penalty=\"l1\",\n",
    "                                   C=c,\n",
    "                                   fit_intercept=False,\n",
    "                                   max_iter=10000,\n",
    "                                   solver=\"liblinear\",\n",
    "                                   random_state=1357);\n",
    "        \n",
    "        model.fit(X_train_bin[cv_train_idx,] , y_train_bin[cv_train_idx])\n",
    "        \n",
    "        for scorer in scorers.keys():\n",
    "            predicted = model.predict(X_train_bin[cv_test_idx,])            \n",
    "            score = scorers[scorer](y_train_bin[cv_test_idx], predicted)\n",
    "            cv_results[s][scorer].append(score)\n",
    "        \n",
    "        cv_results[s][\"dof\"].append(dof(model.coef_))\n",
    "\n",
    "\n",
    "sk_linreg_res = cv_res_to_df(cv_results, scorers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a137bec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sk_linreg_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_best_reg = find_optimal_param(sk_linreg_res, sk_reg_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc5730c",
   "metadata": {},
   "source": [
    "## glmnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c120ca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glmnet import LogitNet\n",
    "\n",
    "glmnet_reg_params = np.concatenate((np.linspace(1,10,10)[::-1], np.logspace(1, 15, 20, base=0.5)))\n",
    "cv_results = dict()\n",
    "\n",
    "for i, (cv_train_idx, cv_test_idx) in enumerate(kf.split(X_train_bin, y_train_elong)):\n",
    "    \n",
    "    s = \"split_%s\" % i\n",
    "    print(s)\n",
    "\n",
    "    cv_results[s] = dict()\n",
    "    cv_results[s][\"dof\"] = []\n",
    "    for scorer in scorers.keys():\n",
    "        cv_results[s][scorer] = []\n",
    "    \n",
    "    for l in glmnet_reg_params:\n",
    "        model = LogitNet(alpha=1,\n",
    "                         lambda_path=[l],\n",
    "                         fit_intercept=False,\n",
    "                         standardize=False,\n",
    "                         random_state=1234,\n",
    "                         max_iter=10000)\n",
    "\n",
    "        model.fit(X_train_bin[cv_train_idx,] , y_train_bin[cv_train_idx])\n",
    "\n",
    "        for scorer in scorers.keys():\n",
    "            predicted = model.predict(X_train_bin[cv_test_idx,])            \n",
    "            score = scorers[scorer](y_train_bin[cv_test_idx], predicted)\n",
    "            cv_results[s][scorer].append(score)\n",
    "\n",
    "        cv_results[s][\"dof\"].append(dof(model.coef_))\n",
    "\n",
    "glmnet_cv_res = cv_res_to_df(cv_results, scorers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa033b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "glmnet_cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95550326",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "glmnet_best_reg = find_optimal_param(glmnet_cv_res, glmnet_reg_params, lower_increases_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce492e9d",
   "metadata": {},
   "source": [
    "## SGD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebc3f20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from glmnet import LogitNet\n",
    "\n",
    "sgd_reg_params = reg_params\n",
    "cv_results = dict()\n",
    "\n",
    "# fixed model training params\n",
    "max_iter = 50\n",
    "\n",
    "for i, (cv_train_idx, cv_test_idx) in enumerate(kf.split(X_train_bin, y_train_elong)):\n",
    "    \n",
    "    s = \"split_%s\" % i\n",
    "    print(s)\n",
    "\n",
    "    cv_results[s] = dict()\n",
    "    cv_results[s][\"dof\"] = []\n",
    "    for scorer in scorers.keys():\n",
    "        cv_results[s][scorer] = []\n",
    "    \n",
    "    for a in sgd_reg_params:\n",
    "        \n",
    "        model = SGDClassifier(loss=\"log_loss\",\n",
    "                              penalty=\"l1\",\n",
    "                              alpha=a,  # = lambda in paper!! Very important to tune for the desired sparsity!\n",
    "                              fit_intercept=False,\n",
    "                              random_state=121,\n",
    "                              n_jobs=1)\n",
    "        cur_iter = 0\n",
    "\n",
    "        while cur_iter < max_iter:\n",
    "            cur_iter += 1\n",
    "\n",
    "            # fit from samples of the big matrix\n",
    "            # TODO: Sampling from the big matrix directly is just for PoP,\n",
    "            # and eliminates the purpose. Only the binarized y-vector should\n",
    "            # be created and the indexes taken from the log count matrix.\n",
    "            rng.shuffle(cv_train_idx)\n",
    "            model.partial_fit(X_train_bin[cv_train_idx,], y_train_bin[cv_train_idx], classes=np.unique(y_batch))\n",
    "\n",
    "        for scorer in scorers.keys():\n",
    "            predicted = model.predict(X_train_bin[cv_test_idx,])            \n",
    "            score = scorers[scorer](y_train_bin[cv_test_idx], predicted)\n",
    "            cv_results[s][scorer].append(score)\n",
    "\n",
    "        cv_results[s][\"dof\"].append(dof(model.coef_))\n",
    "\n",
    "sgd_cv_res = cv_res_to_df(cv_results, scorers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954db7a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sgd_cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca62f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_best_reg = find_optimal_param(sgd_cv_res, sgd_reg_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab747a6",
   "metadata": {},
   "source": [
    "## Compare Fits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab5ca22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "steps = list(range(len(reg_params)))\n",
    "legend = [\"glmnet\", \"sklinreg\", \"sgd\"]\n",
    "\n",
    "p0 = fig.add_subplot(131)\n",
    "p0.plot(steps, glmnet_cv_res[(\"mean\", \"dof\")], label=legend[0])\n",
    "p0.plot(steps, sk_linreg_res[(\"mean\", \"dof\")], label=legend[1])\n",
    "p0.plot(steps, sgd_cv_res[(\"mean\", \"dof\")], label=legend[2])\n",
    "p0.set_ylabel(\"DoF\")\n",
    "p0.legend()\n",
    "\n",
    "p1 = fig.add_subplot(132)\n",
    "p1.plot(steps, glmnet_cv_res[(\"mean\", \"accuracy\")], label=legend[0])\n",
    "p1.plot(steps, sk_linreg_res[(\"mean\", \"accuracy\")], label=legend[1])\n",
    "p1.plot(steps, sgd_cv_res[(\"mean\", \"accuracy\")], label=legend[2])\n",
    "p1.set_ylabel(\"Accuracy\")\n",
    "p1.legend()\n",
    "\n",
    "p2 = fig.add_subplot(133)\n",
    "p2.plot(steps, glmnet_reg_params, label=legend[0])\n",
    "p2.plot(steps, sk_reg_params, label=legend[1])\n",
    "p2.plot(steps, sgd_reg_params, label=legend[2])\n",
    "p2.set_yscale(\"log\")\n",
    "p2.set_ylabel(\"Regularization\")\n",
    "p2.legend()\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdfc66a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
